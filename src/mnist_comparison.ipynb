{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf5fefd",
   "metadata": {},
   "source": [
    "Project: MNIST Digit Classification\n",
    "File Name: mnist_comparison.ipynb\n",
    "Author: Emily Au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0474d90",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"TensorFlow: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d86e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoaders (Windows fix)\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model_pt = MNISTNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_pt = optim.Adam(model_pt.parameters(), lr=1e-3)\n",
    "\n",
    "# Train 5 epochs\n",
    "EPOCHS = 5\n",
    "model_pt.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer_pt.zero_grad()\n",
    "        logits = model_pt(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_pt.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'PyTorch Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}')\n",
    "\n",
    "# Test\n",
    "model_pt.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        pred = model_pt(x_batch).argmax(1)\n",
    "        correct += (pred == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "pt_acc = 100 * correct / total\n",
    "print(f'PyTorch: {pt_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7635a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype('float32')/255., x_test.astype('float32')/255.\n",
    "x_train, x_test = x_train.reshape(60000,784), x_test.reshape(10000,784)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(BATCH_SIZE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "model_tf = keras.Sequential([layers.Dense(128, activation='relu', input_shape=(784,)), layers.Dense(10)])\n",
    "model_tf.compile(optimizer=keras.optimizers.Adam(1e-3), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model_tf.fit(train_ds, epochs=5, validation_data=val_ds, verbose=1)\n",
    "\n",
    "_, tf_acc = model_tf.evaluate(val_ds, verbose=0)\n",
    "print(f'TensorFlow: {tf_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed563a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Framework': ['PyTorch', 'TensorFlow'],\n",
    "    'Lines': [89, 58],\n",
    "    'Style': ['Imperative', 'Declarative'],\n",
    "    'Accuracy': [f'{pt_acc:.2f}%', f'{tf_acc*100:.2f}%']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e1281",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model_pt.state_dict(), 'mnist_pytorch.pt')\n",
    "model_tf.save('mnist_tf.keras')\n",
    "print('Models saved!')\n",
    "print('- PyTorch: mnist_pytorch.pt')\n",
    "print('- TensorFlow: mnist_tf.keras')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
